\documentclass[%
]{beamer}
\usepackage{graphicx} % For including single page pdfs
\usepackage{bm}       % bold math
\usepackage{pgffor}   % for loop
\usepackage{tikz}
\usepackage{multimedia}
\usepackage{layouts}
\usepackage{hyperref}
\usepackage{cambridge_lecture}

\include{include/beamer_commands}
\usepackage{layouts}



\title{Quantifying cosmological tensions}
\subtitle{Interpreting the DES evidence ratio}
\author[Handley] % (optional, for multiple authors)
{Will Handley\\ \small{wh260@cam.ac.uk}}
\institute[University of Cambridge] % (optional)
{%
Astrophysics Group \\
Cavendish Laboratory \\
University of Cambridge
}
\date{24\textsuperscript{th} July 2019}

% Abstract
% --------
% Observational cosmology is close to breaking point. There is now a 4.9-sigma
% tension between the expansion rate $H_0$ as inferred by CMB modelling and
% $H_0$ as measured by supernovae observers. Other parameter tensions
% potentially exist between alternative combinations of data, such as a DES and
% Planck ($S_8$ and $\Omega_m$), or Planck CMB and lensing ($\Omega_K$). In
% these cases it is less obvious how to quantify the level of tension in terms
% of ``sigma'', either due to the high dimensionality of the space, or the
% non-gaussianity of the distributions. Diagnosing the location and level of
% these tensions could prove critical in determining their cause.
%
% In this talk I will discuss recent research by Pablo Lemos and myself into
% novel statistical ways to measure these tensions, how to quantify the number
% of parameters a given experiment constrains, the calibration of the DES
% evidence ratio and the problems with principle component analysis (PCA).


\begin{document}

\begin{frame}
    \titlepage{}
    \begin{center}
    Handley \& Lemos \arxiv{1902.04029}, \arxiv{1903.06682}

    \vspace{10pt}
    \url{github.com/williamjameshandley/anesthetic}
    \end{center}
\end{frame}

%\begin{frame}
%    \frametitle{Outline}
%    \tableofcontents
%\end{frame}

\begin{frame}
    \frametitle{The Hubble $H_0$ tension}
    \begin{columns}
        \begin{column}{0.5\textwidth}
        \begin{itemize}
            \item CMB cosmologists (Planck) infer \\ $H_0=67\pm0.5\text{ km s}^{-1} \text{Mpc}^{-1}$
            \item Supernovae data  ($SH_0ES$) measure \\ $H_0=74\pm1.4 $
            \item $>4\sigma$ discrepancy could be due to:
                \begin{itemize}
                    \item Systematic error
                    \item Problem with standard model of cosmology ($\Lambda$CDM)
                \end{itemize}
            \item Inconsistent datasets shouldn't be combined
        \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{overlayarea}{\textwidth}{0.5\textheight}
            \includegraphics<1>{./plots/H0.pdf}
            \includegraphics<2>{./plots/H0_combined.pdf}
            \end{overlayarea}
        \end{column}
    \end{columns}
\end{frame}


\begin{frame}
    \frametitle{$\sigma_8$-$\Omega_m$ tension}
    \begin{columns}
        \begin{column}{0.5\textwidth}
        \begin{itemize}
            \item<1-> Matter density $\Omega_m$ and RMS matter fluctuations $\sigma_8$ are constrained by 
            \item<1-> BAO and Planck look consistent
            \item<2-> DES is less clear
            \item<2-> How do you define a tension in terms of ``sigma'' for this case?
        \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{overlayarea}{\textwidth}{0.5\textheight}
            \includegraphics<1>{./plots/BAO_planck.pdf}
            \includegraphics<2>{./plots/DES_planck.pdf}
            \end{overlayarea}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{$\Omega_K$ tension}
    \begin{columns}
        \begin{column}{0.5\textwidth}
        \begin{itemize}
            \item Models with spatial curvature $\Omega_K$.
            \item Best-kept secret of Planck: only $1/10,000$ MCMC samples $\Omega_K>0$.
            \item How consistent do Planck and CMB lensing look?
            \item Await likelihood release (beginning of next month)
        \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{overlayarea}{\textwidth}{0.5\textheight}
            \includegraphics<1>{./plots/curvature.pdf}
            \includegraphics<2>{./plots/H0_combined.pdf}
            \end{overlayarea}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Quantifying tension}
    \framesubtitle{Gaussians}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            For 1D Gaussian distributions, tension is pretty easy to define:
            \[
                X = \frac{\mu_A - \mu_B}{\sqrt{\sigma_A^2 + \sigma_B^2}},
            \]
         where $\mu$ and $\sigma$ are the respective parameter means and standard deviations.
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{overlayarea}{\textwidth}{0.65\textheight}
                \includegraphics{./plots/H0.pdf}
            \end{overlayarea}
        \end{column}
    \end{columns}

    The multivariate $d$-dimensional equivalent to this tension would be:
    \[
        X^2_d = {(\mu_A - \mu_B)}^T{(\Sigma_A + \Sigma_B)}^{-1}(\mu_A-\mu_B),
    \]
    where $\Sigma$ is in general a covariance matrix.
\end{frame}

\begin{frame}
    \frametitle{Quantifying tension}
    \framesubtitle{non-Gaussians}
    \begin{figright}[0.4]{./figures/all_components.pdf}
        Things become less clear when distributions become ``banana like'' (\arxiv{1906.11628}),
        or worse, multimodal.
    \end{figright}
    Many attempts to generalise the Gaussian case result in a parameterisation-dependent quantity.
\end{frame}

\begin{frame}
    \frametitle{Quantifying tension}
    \framesubtitle{High-dimensional spaces}
    \centerline{%
    \includegraphics[width=0.49\textwidth]{./figures/tension.pdf}
    \includegraphics[width=0.49\textwidth]{./figures/tension_rotated.pdf}
    }
    \begin{itemize}
        \item In high dimensions, things can look good when projected into 2D.
        \item We need a systematic way of seeking out tension, without relying on inspired choices of parameters to reveal them
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{The DES evidence ratio $R$}
    \begin{itemize}
        \item The Dark Energy Survey (\arxiv{1708.01530}) quantifies tension between two datasets $A$ and $B$ using the Bayes ratio:
            \[
                R = \frac{\mathcal{Z}_{AB}}{\mathcal{Z}_A \mathcal{Z}_B}
            \]
            where $\mathcal{Z}$ is the Bayesian evidence.
        \item Many attractive properties:
            \begin{itemize}
                \item Symmetry
                \item Parameterisation independence
                \item Dimensional consistency
                \item Use of well-defined Bayesian quantities
            \end{itemize}
        \item What does it mean?
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Bayesian evidence $\mathcal{Z}$}
    \begin{itemize}
        \item Bayes theorem for parameter estimation:
    \[
    P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)} \quad\longrightarrow\quad \text{Posterior} = \frac{\text{Likelihood}\times\text{Prior}}{\text{Evidence}}
    \]
        \item Normalising constant $\equiv$ Bayesian evidence $\equiv$ $P(D)$ is hard to compute:
    \[
        P(D) = \int P(D|\theta)P(\theta) d\theta = \left\langle \text{Likelihood} \right\rangle_\text{Prior}
    \]
        \item Traditionally used to compare models using the same data
        \item For DES, it is used to compare different data with the same model.
        \item Computed using nested sampling (\texttt{MultiNest}, \texttt{PolyChord}, \texttt{dynesty}), simulated annealing (\texttt{emcee}), or from MCMC using \texttt{MCEvidence}.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Bayesian evidence $\mathcal{Z}$: Prior dependency}
    \begin{itemize}
        \item Bayesian evidences are prior dependent:
            \[
                \mathcal{Z} = \int P(D|\theta)P(\theta) d\theta \approx \langle\text{Likelihood}\rangle_\text{Posterior} \times \frac{\text{Posterior volume}}{\text{Prior volume}}
            \]
        \item They balance ``goodness of fit'' via likelihood with ``complexity'' through Occam penalty.
        \item Models that include too many fine-tuned parameters are disfavoured, unless they provide a much better fit.
        \item Corollary: Unconstrained parameters are not penalised.
        \item Widen prior $\Rightarrow$ reduce evidence \\ (providing prior does not cut into posterior).
        \item Bayesians vs Frequentists $\leftrightarrow$ Feature vs Bug.
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{The meaning of the DES evidence ratio $R$}
    \begin{itemize}
        \item The Dark Energy Survey collaboration (\arxiv{1708.01530}) quantify tension between two datasets $A$ and $B$ using the Bayes ratio:
            \[
                R = \frac{\mathcal{Z}_{AB}}{\mathcal{Z}_A \mathcal{Z}_B} = \frac{P(A\cap B)}{P(A)P(B)} = \frac{P(A|B)}{P(A)} = \frac{P(B|A)}{P(B)}
            \]
        \item $R$ gives the relative change in our confidence in data $A$ in light of having seen $B$ (and vice-versa).
        \item $R>1$ implies we have more confidence in $A$ having received $B$.
        \item Like evidences, it is prior-dependent
        \item Increasing prior widths $\Rightarrow$ increasing confidence.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{The DES evidence ratio $R$: Prior dependency}
    {\includegraphics[trim=0.6in 0.3in 0in 0in]{./plots/prior_dependency.pdf}}
    \begin{itemize}
        \item What does it mean if increasing prior widths $\Rightarrow$ increasing confidence? 
        \item Wide priors mean {\em a-priori\/} the parameters could land anywhere.
        \item We should be proportionally more reassured when they land close to one another if the priors are wide
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{How do we deal with the prior dependency in $R$?}
    \begin{description}
        \item[Option 1] Take the Bayesian route, accept the prior dependency, and spend time trying to justify why a given set of priors are ``physical''.
        \item[Option 2] Try to find a principled way of removing this prior dependency
    \end{description}
    \begin{itemize}
        \item One of the critical observations is that one can only hide tension by widening priors. Narrowing them will only ever show tension if it is present.
        \item If we could define ``Narrowest reasonable priors'' and find that $R<1$, then this would indicate tension.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{$R$: a Gaussian example}
    \begin{itemize}
        \item Given two Gaussians with parameter means $\mu_A,\mu_B$ and parameter covariances $\Sigma_A,\Sigma_B$ and a prior with volume $V_\pi$:
            \begin{align}
                \log R =& -\frac{1}{2} (\mu_A-\mu_B){(\Sigma_{A}+\Sigma_{B})}^{-1}(\mu_A-\mu_B)\nonumber\\
                & + \log V_\pi\nonumber -\log\sqrt{|2\pi(\Sigma_{A}+\Sigma_{B})|} 
            \end{align}
        \item Like evidence, $R$ composed of ``Goodness of fit'', and ``Occam factor''.
        \item Ideally want would remove this Occam factor (ratio of prior to posterior volume).
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{KL divergence $\mathcal{D}$, Information $\mathcal{I}$, suspiciousness $S$}
    \begin{itemize}
        \item The KL divergence quantifies the compression from prior to posterior:
            \[
                \mathcal{D} = \int P(\theta|D) \log \frac{P(\theta|D)}{P(\theta)} d\theta = \left\langle\log\frac{\text{Posterior}}{\text{Prior}}\right\rangle_\text{Posterior}
            \]
        \item It bears many similarities to an Occam factor, for a Gaussian:
            \[
                \mathcal{D} =   \log V_\pi - \log \sqrt{|2\pi\Sigma|} - \frac{1}{2}d
            \]
        \item Can define equivalent of $R$ for KL divergence, the information ratio $\mathcal{I}$
            \begin{align}
                \log R &= \mathcal{Z}_{AB} -\mathcal{Z}_A - \mathcal{Z}_B \nonumber\\
                \log \mathcal{I} &= \mathcal{D}_A + \mathcal{D}_B - \mathcal{D}_{AB} \nonumber
            \end{align}
        \item Subtracting the two removes prior dependency, giving suspiciousness:
            \[
                \log S = \log R - \log \mathcal{I}
            \]
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Suspiciousness $S$}
    \begin{itemize}
        \item For a Gaussian:
            \[
                \log S = \frac{d}{2}  -\frac{1}{2} (\mu_A-\mu_B){(\Sigma_{A}+\Sigma_{B})}^{-1}(\mu_A-\mu_B).
            \]
        \item We thus find that our original idea for tension $X^2_d=d-2\log S$.
        \item However $S$ is composed of evidences $\mathcal{Z}$ and KL divergences $\mathcal{D}$, which are Gaussian-independent concepts.
        \item The only thing remaining to determine is $d$, the ``number of parameters''.
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Dimensionality $d$}
    \centerline{%
    \includegraphics[width=0.49\textwidth]{./figures/dimensions_1.pdf}
    \includegraphics[width=0.49\textwidth]{./figures/dimensions_2.pdf}
    }
    \begin{itemize}
        \item Intuition should tell us that the $d$ we need is the effective number of parameters (i.e.\ should not include unconstrained ones).
        \item Like the evidence, or the KL divergence, this ``Model dimensionality'' should be a sought-after inference quantity.
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Dimensionality $\tilde{d}$}
    \begin{itemize}
        \item KL divergence is the mean of the Shannon information $I$:
            \begin{align}
                \mathcal{D} &= \int P(\theta|D) \log \frac{P(\theta|D)}{P(\theta)} d\theta = \left\langle\log\frac{\text{Posterior}}{\text{Prior}}\right\rangle_\text{Posterior}\nonumber\\
                I &= \log\frac{\text{Posterior}}{\text{Prior}}\nonumber
            \end{align}
        \item Model dimensionality proportional to variance of Shannon information:
            \[
                \frac{\tilde{d}}{2} = \text{var}\left(\frac{\text{Posterior}}{\text{Prior}}\right)_\text{Posterior}
            \]
        \item Examples from real data:
            \begin{align}
                \tilde{d}_\text{Planck} &= 15.8 \pm  0.3 &(21) \nonumber\\
                \tilde{d}_\text{DES} &= 14.0 \pm  0.3 &(26) \nonumber\\
                \tilde{d}_\text{BAO} &= 2.95 \pm  0.07 &(6) \nonumber\\
                \tilde{d}_\text{S$H_0$ES} &= 0.93 \pm  0.03 &(6) \nonumber
            \end{align}
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Headline results}
    \begin{itemize}
        \item Can calibrate $X^2_d$ as on the same scale as $\chi^2_d$ to give a $p$-value-like quantity, termed ``Tension probability'' $p$
            \begin{align}
                \text{Planck+BAO}:&      &p&=  42 \pm     4 \% \nonumber\\
                \text{Planck+DES}:&      &p&=   3.2 \pm     1.0 \% \nonumber\\
                \text{Planck+S$H_0$ES}:& &p&=   0.25 \pm     0.17 \% \nonumber
            \end{align}
        \item Under this metric, S$H_0$ES is unambiguously inconsistent, although not quite as brutal as $>4\sigma$. BAO is consistent, and $DES$ is inconsistent, but only just. This is pleasingly similar to ones intuition.
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Extensions}
    \begin{itemize}
        \item In light of these results, there are two natural questions to ask:
    \end{itemize}
    \begin{enumerate}
        \item $\tilde{d}_\text{BAO} = 2.95 \pm  0.07 $ out of a possible 6. Which $\sim 3$ are these?
        \item Is there a direction in parameter space which is ``most in tension''
    \end{enumerate}
    \begin{itemize}
        \item These are questions which people would usually answer with a PCA-type approach.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{The problem with Principle Component Analysis}

    \begin{figright}[0.6]{./plots/pca.pdf}
        \begin{itemize}
            \item Compute eigenvectors and eigenvalues of covariance matrix.
            \item These aim to describe ``directions'' in parameter space
            \item This procedure is not covariant:
        \end{itemize}
    \end{figright}
    \begin{quote}
        "Principal Component Analysis" is a dimensionally invalid method that gives people a delusion that they are doing something useful with their data. If you change the units that one of the variables is measured in, it will change all the "principal components"! It's for that reason that I made no mention of PCA in my book. I am not a slavish conformist, regurgitating whatever other people think should be taught. I think before I teach. David J C MacKay.

        \end{quote}
\end{frame}

\begin{frame}
    \frametitle{Conclusions}
    \begin{itemize}
        \item The DES ratio $R$ is a principled thing to work with, but its prior dependency must be acknowledged
        \item Using KL divergences and model dimensionalities, $R$ may be calibrated into something akin to the tension we desire.
        \item The ``inference triple'' of $\mathcal{Z},\mathcal{D},\tilde{d}$ should be considered in all model comparison analyses.
        \item All three can be computed from nested sampling runs using the \texttt{anesthetic} package.
        \item Be careful when applying principle component analysis!
    \end{itemize}
\end{frame}
\end{document}
